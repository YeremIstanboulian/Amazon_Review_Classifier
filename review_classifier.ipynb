{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data to pandas dataframes\n",
    "train = pd.read_csv('training.txt', header = None)\n",
    "train = train.rename(columns={0: \"text\", 1: \"good\"})\n",
    "X_train = train['text']\n",
    "y_train = train['good']\n",
    "test = pd.read_csv('testing.txt', header = None)\n",
    "test = test.rename(columns={0: \"text\", 1: \"good\"})\n",
    "X_test = test['text']\n",
    "y_test = test['good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Naive bayes algorithm\n",
    "start_nb = time.time()\n",
    "cv = CountVectorizer(stop_words = \"english\")\n",
    "train_cv = cv.fit_transform(X_train)\n",
    "test_cv = cv.transform(X_test)\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_cv, y_train)\n",
    "predictions = mnb.predict(test_cv)\n",
    "end_nb = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8460076045627376\n",
      "Precision: 0.8505747126436781\n",
      "Recall: 0.8363269424823411\n",
      "Time: 5.734030723571777 seconds\n"
     ]
    }
   ],
   "source": [
    "# Report results\n",
    "print('Accuracy:', accuracy_score(y_test, predictions))\n",
    "print('Precision:', precision_score(y_test, predictions))\n",
    "print('Recall:', recall_score(y_test, predictions))\n",
    "print('Time:', (end_nb - start_nb), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['game' 'just' 'like' 'games' 'play' 'time' 'don' 'really' 'good' 'fun']\n",
      "['game' 'like' 'games' 'play' 'just' 'great' 'good' 'fun' 'time' 'really']\n"
     ]
    }
   ],
   "source": [
    "neg_class_prob_sorted = mnb.feature_log_prob_[0, :].argsort()[::-1]\n",
    "pos_class_prob_sorted = mnb.feature_log_prob_[1, :].argsort()[::-1]\n",
    "\n",
    "print(np.take(cv.get_feature_names(), neg_class_prob_sorted[:10]))\n",
    "print(np.take(cv.get_feature_names(), pos_class_prob_sorted[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_features(vectorizer,classifier,n=10):\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names =vectorizer.get_feature_names()\n",
    "    diff_neg = sorted(zip(np.exp(classifier.feature_log_prob_[0]) - np.exp(classifier.feature_log_prob_[1]), feature_names),reverse=True)[:n]\n",
    "    diff_pos = sorted(zip(np.exp(classifier.feature_log_prob_[1]) - np.exp(classifier.feature_log_prob_[0]), feature_names),reverse=True)[:n]\n",
    "\n",
    "    print(\"Important words in negative reviews\")\n",
    "\n",
    "    for coef, feat in diff_neg:\n",
    "        print(feat)\n",
    "\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Important words in positive reviews\")\n",
    "\n",
    "    for coef, feat in diff_pos:\n",
    "        print(feat)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important words in negative reviews\n",
      "just\n",
      "game\n",
      "bad\n",
      "money\n",
      "don\n",
      "-----------------------------------------\n",
      "Important words in positive reviews\n",
      "great\n",
      "fun\n",
      "best\n",
      "love\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "important_features(cv,mnb,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a new review to predict its sentiment: not the best game out there\n",
      "----------------------------------------------------------------------------------\n",
      "Prediction is positive review\n"
     ]
    }
   ],
   "source": [
    "com = input('Enter a new review to predict its sentiment: ')\n",
    "print('----------------------------------------------------------------------------------')\n",
    "com_series = pd.Series(com)\n",
    "user_cv = cv.transform(com_series)\n",
    "com_prediction = mnb.predict(user_cv)\n",
    "if(com_prediction == 1):\n",
    "    print(\"Prediction is positive review\")\n",
    "else:\n",
    "    print(\"Prediction is negative review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
